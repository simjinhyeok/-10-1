\chapter{魚眼カメラによる計測のための画像処理}
\label{chap:ImageProcessing}
\minitoc

\thispagestyle{empty}

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{はじめに}
\label{sec:}

本章では，魚眼カメラで取得した画像によってオーロラの3次元計測を行うために用いる座標系や必要なパラメータ，画像処理について述べる．
%本研究では，地上の異なる複数地点に魚眼カメラを設置し，時刻同期をとってオーロラを撮影した画像を入力画像とする．
%入力画像のうち1対の入力画像を用いてオーロラのステレオ計測を行うが，カメラの位置や姿勢が異なるため2台のカメラに共通な座標系を設ける．これをリクティファイド座標系と呼ぶ．
%設置された位置や姿勢の異なる2台のカメラ画像を用いてステレオ計測を行うため，2台のカメラに共通な座標系を設け，これをリクティファイド座標系と呼ぶ．
%本研究では魚眼画像を用いた計測を簡単にするために，画像処理によって入力画像をリクティファイド座標系画像へ変換し，さらに魚眼レンズに起因する歪みを除去し透視投影画像へと変換する．
%魚眼画像は魚眼レンズの光学モデルによって変化するため，使用する魚眼レンズのモデルに基づいて画像の座標変換や歪みの除去を行う．
%また，画像を変換する際に必要なカメラの内部パラメータや外部パラメータを推定する．\\

まず\ref{sec:rectified}節で本研究で魚眼画像対を平行ステレオペアとして扱うために用いるリクティファイド座標系について述べる．

次に\ref{sec:fisheye_model}節では，一般的な魚眼カメラのモデルと本研究で定義した魚眼カメラのモデルについて述べる．

\ref{sec:calibration}節で本研究における画像処理に必要なパラメータと，それらの推定方法について述べる．

\ref{sec:translation}節では入力画像対を平行ステレオ画像対へと変換する手法について述べる．画像の変換には\ref{sec:calibration}節で推定したパラメータを用いる．

%その座標系への画像の変換方法について述べる．変換には\ref{sec:calibration}節で推定したパラメータを用いる．

最後に\ref{sec:undistortion}節では入力画像から魚眼レンズによる歪みを取り除き，透視投影画像へと変換する手法について述べる．
%最後に\ref{sec:backsubtraction}節では，特徴点検出のために画像中からオーロラ領域を抽出する背景差分について述べる．
\clearpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{リクティファイド座標系}
\label{sec:rectified}

本研究では地上の異なる複数地点に魚眼カメラを設置し，全てのカメラで時刻同期をとって撮影したオーロラの画像を入力画像とする．
複数地点から撮影した入力画像のうち，2地点から撮影した1対の入力画像を用いてステレオ計測を行う．
ステレオ計測では一般的に，効率と精度を向上させるためにエピポーラ幾何と呼ばれる幾何学的な拘束条件が用いられる[引用予定]．%このエピポーラ拘束を画像上で簡単に扱えるという理由から，カメラを平行に設置した平行ステレオ計測が
本研究では，エピポーラ拘束の画像上での扱いを容易にするために，カメラを平行に設置した平行ステレオ計測を行う．
しかしオーロラは高度100 km以上の上空で発生するため[引用]，三角測量による計測に十分な視差を得るために2台のカメラは大きく距離をおいて設置する必要がある．
そのため2台のカメラの姿勢を設置時に調節することによって正確な平行ステレオペアにすることは困難である．
そこで画像処理により入力画像対を平行ステレオ画像対へと変換する必要がある．\\
%しかしオーロラは高度100 km以上の上空に発生する現象であるため[引用予定]，ステレオ計測するためにはカメラ間の距離を非常に大きくする必要があり，カメラを平行ステレオペアにすることは困難である．そこで画像処理によって入力画像対を平行ステレオ画像対へと変換する必要がある．\\

入力画像対を平行ステレオ画像対へと変換するために，2台のカメラに共通な座標系を設ける．
この座標系をリクティファイド座標系と呼ぶ．
リクティファイド座標系の原点をカメラAの光学中心とする．X軸をカメラAの光学中心からカメラBの光学中心へ向かう方向と定義する．
X軸とY軸に垂直で，地表から天頂方向に向かう向きにZ軸をとる．
また，Y軸は右手系に従い，原点における地表面の設置平面でX軸に垂直な方向と定義する．\\

各カメラの姿勢とリクティファイド座標系の関係を図\ref{fig:shisei1}に示す．
設置されたカメラAの光軸を$Z_A$で表し，$X_A$軸，$Y_A$軸は得られる画像の座標軸に平行な軸を表している．カメラBに関しても同様に表している．
黒い矢印で表した軸がリクティファイド座標系の各軸を表している．
各カメラの座標軸をリクティファイド座標系の軸と一致するように変換することで，魚眼カメラから得られた画像によってステレオ計測を行える．\\

リクティファイド座標系に基づいた平行ステレオペアとなるようなカメラ姿勢の変換について図\ref{fig:shisei2}に示す．
図\ref{fig:shisei2}において赤い四角は設置されたカメラの姿勢，赤い矢印はカメラの光軸を表している．
一方，青い四角は各カメラがリクティファイド座標系において平行ステレオの関係にあるときの姿勢である．
カメラ間距離を$d$とすると，リクティファイド座標系においてカメラAの座標は$(0, 0, 0)$，カメラBの座標は$(d, 0, 0)$と表される．

\clearpage

（図修正予定）

\begin{figure}[hbp]
\begin{center}
\includegraphics[width=10cm]{./chap3/eps/camera_zahyou2.eps}
\vspace{5mm}
\caption{カメラの座標系とリクティファイド座標系の関係}
\label{fig:shisei1}
\end{center}
\end{figure}

%\subsection{リクティファイド座標系への入力画像変換}
%\label{ssec:rectification}
\begin{figure}[hbp]
\begin{center}
\includegraphics[width=8cm]{./chap3/eps/posture_trans.eps}
\caption{リクティファイド座標系へのカメラ姿勢の変換}
\label{fig:shisei2}
\end{center}
\end{figure}

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{魚眼レンズのモデル}
\label{sec:fisheye_model}

魚眼レンズとは，一般的に約180{\circ}の画角を持ったレンズのことを指すが，射影方式によっていくつかの種類に分類される．
例えばレンズを半球面と仮定した場合に，半球上の図形をそのまま平面に射影する正射影方式や，球面上の距離が正しく投影され画角による解像度の違いのない等距離射影方式，像の面積が立体角に比例する等立体角射影方式などの射影方式が存在する．
魚眼カメラによって撮影された画像が持つ特有の歪みは，レンズの射影方式によって異なる．
画像中心($C_u$, $C_v$)からのピクセル距離を$r$ [pixel]，カメラ光軸から入射光への角度を$\theta$ [$^{\circ}$]，魚眼レンズの歪みパラメータを$k$ [pixel]とおくとき，
射影方式による歪みパラメータは表のようになる．

\begin{table}[h]
\begin{center}
\caption{撮影場所}
\label{table:camera_position}
\begin{tabular}{|c|c|}
\hline
正射影方式 & r=k\sin{\theta} \\ \hline
等距離射影方式 & r=k{\theta} \\ \hline
等立体角射影方式 & r=2k\sin{\frac{\theta}{2}} \\ \hline
\end{tabular}
\end{center}
\end{table}

円周魚眼，対角魚眼
一般的な各モデル
歪みの違いを考慮し5次式で表すとする



\clearpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{カメラキャリブレーション}
\label{sec:calibration}
魚眼カメラを通して撮影した画像は，レンズにより歪みが生じている．この歪みを補正するためにレンズ固有のパラメータを推定する必要がある．
%また，\ref{sec:rectified_coordinate}節で詳しく述べるが，本研究ではステレオ計測を行うために2台のカメラで共通した座標系を設定する．
また，各カメラで取得した画像をリクティファイド座標系における画像へと変換するためにカメラの位置や姿勢を推定する必要がある．

そこで，本節では図\ref{fig:parameter}の通り，レンズ固有の内部パラメータである
画像中心および歪みパラメータの推定手法を\ref{sec:internal_parameter}項，外部パラメータであるカメラの位置パラメータや姿勢の回転パラメータの推定手法を\ref{sec:external_parameter}項にて述べる．

\vspace{1cm}

\begin{figure}[hbp]
\begin{center}
\includegraphics[width=10cm]{./chap2/parameter.eps}
\caption{推定するパラメータ}
\label{fig:parameter}
\end{center}
\end{figure}

\clearpage
%\clearpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{内部パラメータの推定}
\label{sec:internal_parameter}

本研究において必要となる魚眼カメラの内部パラメータは，
\begin{itemize}
\item 画像中心（レンズ中心から結像面への垂線と結像面との交点）：$C_u$，$C_v$
\item 魚眼レンズの歪みパラメータ：$k$
\end{itemize}
である．これらの推定手法を以下で述べる．
%\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{画像中心の推定}

本研究では，画像中心の推定にScaramuzzaらの手法を使用する\cite{scaramuzza2006}．
%推定は以下の手順で行う．
%（簡単に手順を書く）
撮影装置を設置，固定した後，格子パターンを撮影可能範囲内で移動させながら様々な向き角度で撮影する．これにより図\ref{fig:Ocam}に示すような画像を取得し，10枚程度を入力画像とする．これにより魚眼カメラで取得される画像の画像中心の座標($C_u$, $C_v$)を推定する．

\vspace{1cm}

\begin{figure}[hbp]
\begin{center}
\includegraphics[width=11cm]{./chap2/ocamcalib.eps}
\caption{画像中心の推定に使用する入力画像}
\label{fig:Ocam}
\end{center}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{魚眼レンズの歪みパラメータの推定}

魚眼レンズの歪みパラメータの推定には，式(\ref{eq:model})を変形することにより得られる式(\ref{eq:distortion})を用いる．

\begin{equation}
k = \frac{r}{ 2\sin{\frac{\theta}{2}} }
\label{eq:distortion}
\end{equation}

この式において，$\theta=90^{\circ}$のときの画像中心からのピクセル距離$r$は画像半径となっているため，画像半径を得ることができれば歪みパラメータを推定することができる．
しかしながら画像中の撮影領域の境界は不鮮明で，画像半径を計測することは困難である．

そこで魚眼レンズの歪みパラメータの推定に，図\ref{fig:chokusen}に示すような平行直線パターンを用いる．撮影装置で平行直線をパターンを撮影し，得られた画像の消失点を利用し歪みパラメータを推定する\cite{中野2007}．

魚眼レンズにより平行直線パターンを撮影すると歪みが生じるが，全ての直線は互いに平行なためカメラの光軸から90$^{\circ}$の点で消失点を持つ．
式(\ref{eq:distortion})に$\theta=90^{\circ}$と，推定した画像中心から消失点までのピクセル距離$r$を代入することにより，魚眼レンズの歪みパラメータを推定することができる．


\begin{figure}[hbp]
\begin{center}
\includegraphics[width=11cm]{./chap2/chokusen.eps}
\caption{歪みパラメータの推定に使用する入力画像}
\label{fig:chokusen}
\end{center}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\clearpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{外部パラメータの推定}
\label{sec:external_parameter}

本研究において必要となる魚眼カメラの外部パラメータは，
\begin{itemize}
\item 各カメラの位置パラメータ（緯度，経度，高度）
\item 各カメラの姿勢を共通の座標系における姿勢へ変換するために必要な回転パラメータ：$R$
\end{itemize}
である．これらの推定手法を以下で述べる．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{位置パラメータの推定}
\label{ssec:position}
本研究では，使用する撮影装置にGPSユニットを搭載する．これにより，撮影装置を設置した場所の緯度，経度，高度といったGPS情報が取得した画像に付加され，各カメラの位置パラメータを取得することが可能である．

GPSユニットによって得る各カメラの位置パラメータを利用し，リクティファイド座標系におけるカメラ間距離$d$を推定する．また\ref{ssec:rotation}条で詳細に述べるが，各カメラが取得する画像をリクティファイド座標系での画像へ変換するために，一方のカメラから他方のカメラへの方位角と仰角が必要である．これらも位置パラメータを利用して推定する．

2台のカメラは10km前後の位置に設置されているため，地表を平面と近似する．2台のカメラとカメラ間距離，方位角，仰角の関係を図\ref{fig:camera_distance}に示す．図\ref{fig:camera_distance}に示す通り，カメラＡとカメラＢの緯度差，経度差，高度差を用いてカメラ間距離$d$，方位角，仰角を算出する．
\vspace{1cm}

\begin{figure}[hbp]
\begin{center}
\includegraphics[width=12cm]{./chap2/camera_distance.eps}
\caption{カメラ間距離$d$，方位角，仰角の推定}
\label{fig:camera_distance}
\end{center}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{カメラ姿勢合わせのための回転パラメータ推定}
\label{ssec:rotation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ref{ssec:position}条にて各カメラの位置パラメータの取得について述べたが，GPSユニットから得られる情報では各位置におけるカメラの姿勢を識別することはできない．
カメラの姿勢を識別しリクティファイド座標系にて各カメラを平行ステレオの関係に変換するため，以下の手法により回転パラメータを推定する．

本研究では，星の位置を利用することで回転パラメータを推定する．
撮影される画像中で明確に確認できるN個の恒星を手動で指定し，画像中の星への方向ベクトルと，リクティファイド座標系における星への方向ベクトルを比較することによって推定する．
%本研究では画像中で明確に確認できるN個の恒星を手動で指定する．

画像を取得した際のカメラ座標系における，観測地点からN個の各星に向かう方向の単位ベクトルを$\mathbf{n_1}$，$\mathbf{n_2}$...$\mathbf{n_{\it i}}$とし，
リクティファイド座標系での観測地点からN個の各星へ向かう方向の単位ベクトルを$\mathbf{m_1}$，$\mathbf{m_2}$...$\mathbf{m_{\it i}}$とする（ただし$i = 1, 2, ..., N$）．
%$(x_1, y_1, z_1)$，$(x_2, y_2, z_2)$...$(x_i, y_i, z_i)$（ただし$i = 1, 2, ..., N$）とする．
%また，リクティファイド座標系での観測地点からN個の各星へ向かう方向の単位ベクトルをそれぞれ$(X_1, Y_1, Z_1)$，$(X_2, Y_2, Z_2)$...$(X_i, Y_i, Z_i)$（ただし$i = 1, 2, ..., N$）とする．
また，$\mathbf{n_{\it i}} = (x_i, y_i, z_i)^T$，$\mathbf{m_{\it i}} = (X_i, Y_i, Z_i)^T$と表す．
カメラ姿勢と星の方向ベクトルを表した図を図\ref{fig:vector_direction}に示す．
図\ref{fig:vector_direction}における赤色のカメラ姿勢を実際のカメラ姿勢，青色のカメラ姿勢をリクティファイド座標系でのカメラ姿勢とする．
点線の矢印で示された方向がそれぞれの姿勢で取得される画像の画像中心方向である．ここでリクティファイド座標系からカメラ座標系への回転行列を$\mathbf{R}$とすると，
式(\ref{eq:nRm})が成り立つ．
\begin{eqnarray}
\mathbf{n_{\it i}}=\mathbf{Rm_{\it i}}
\label{eq:nRm}
\end{eqnarray}
式(\ref{eq:nRm})より，ベクトル$\mathbf{n_{\it i}}，\mathbf{m_{\it i}}$を求めれば回転パラメータを推定することができる．

%\vspace{1cm}
\begin{figure}[hbp]
\begin{center}
\includegraphics[width=7cm]{./chap2/vector_houkou.eps}
\caption{カメラ姿勢と星の方向ベクトル}
\label{fig:vector_direction}
\end{center}
\end{figure}


\clearpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

画像中の星と，観測地点からその星への方向ベクトルの関係を表した図を図\ref{fig:star_vector}に示す．図\ref{fig:star_vector}中のx軸，y軸，z軸はカメラ座標系の座標軸である．
観測地点から{\it i}番目の星$S_i$への方向ベクトルを赤矢印で表している．画像中心を$(C_u, C_v)$，$S_i$の画像中での位置を$(u_i, v_i)$，画像中心からの画像上の$S_i$までの距離を$r_i$とおく．
観測地点から$S_i$に向かう方向の単位ベクトルの算出するためには，図\ref{fig:star_vector}に示すような星への方向を表す単位ベクトル$(x_i, y_i, z_i)$の極座標表示$(\theta_i，\phi_i)$が求まれば良い．

画像中心からの画像上の星までの距離を$r_i$は次の式(\ref{eq:ruv})により求まる．
\begin{eqnarray}
r_i=\sqrt{ \left(u_i-C_u\right)^{2}+ \left(v_i-C_v\right)^{2}} 
\label{eq:ruv}
\end{eqnarray}

この$r_i$を用いることにより，式(\ref{eq:model})，図\ref{fig:star_vector}から，式（\ref{eq:func_theta1}），（\ref{eq:func_phi1}）によって星の方向ベクトル$(\theta_i，\phi_i)$が算出される．
式（\ref{eq:func_phi1}）はどちらの式を用いても求めることができる．
\begin{equation}
\theta_i = 2\sin^{-1}{\frac{r_i}{2k}}
\label{eq:func_theta1}
\end{equation}

\begin{equation}
\phi_i = \cos^{-1}{\frac{u - C_{u}}{r_i}}, \ \phi_i = \sin^{-1}{\frac{v - C_{v}}{r_i}}
\label{eq:func_phi1}
\end{equation}
求めた星の方向を表す極座標表示の単位ベクトル$(\theta_i，\phi_i)$から，星の方向を表す直交座標表示の単位ベクトル$(x_i, y_i, z_i)$は式(\ref{eq:xyz})により得られる．

\begin{eqnarray}
\mathbf{n_{\it i}}=
\left[\begin{array}{cc}x_i \\ y_i \\ z_i \end{array}\right]=\left[\begin{array}{cc}\sin\theta_i\cos\phi_i \\ \sin\theta_i\sin\phi_i \\ \cos\theta_i \end{array}\right]
\label{eq:xyz}
\end{eqnarray}

%\vspace{1cm}
\begin{figure}[hbp]
\begin{center}
\includegraphics[width=6cm]{./chap2/star_vector.eps}
\caption{星の方向ベクトル}
\label{fig:star_vector}
\end{center}
\end{figure}

\clearpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
リクティファイド座標系における$S_i$への方向の単位ベクトル$\mathbf{m}_i$を求めるためには，撮影した時刻における$S_i$の位置を知る必要があるが，
任意の時刻，位置，方向で観測したときの全ての星の位置は厳密に知ることができる．また，星の位置をプラネタリウム形式で表示し，容易に知ることができるようにしたソフトウェアも多数存在する．
本研究では，その中の1つであるToxsoft社が開発したStella Theater Liteを使用する．本研究にて使用する星の地図（Stella Theater Lite）を図\ref{fig:star_map}に示す．

\vspace{1cm}
\begin{figure}[hbp]
\begin{center}
\includegraphics[width=9cm]{./chap2/StellaTheaterLite2.eps}
\caption{星の地図（Stella Theater Lite）}
\label{fig:star_map}
\end{center}
\end{figure}

\clearpage

星の地図には，\ref{ssec:position}条で取得する観測地点の緯度，経度，写真を撮影する時刻を入力することで，観測地点からこの地図上の任意の星への方位角，仰角を取得することができる．
ただし，この方位角と仰角は世界座標系におけるものである．本論文において，世界座標系はカメラAを原点とし，南へ向かう方向をX'軸，東へ向かう方向をY'軸，X'軸とY軸に垂直で'天頂方向へ向かう方向をZ'軸とする．
図\ref{fig:world_vector}に示すように，方位角はX'軸からY'軸へ向かう角度，仰角はX'Y'平面からZ'軸へ向かう角度とする．
星の地図より得られる方位角，仰角を用いて図\ref{fig:star_vector}における$(\theta_i，\phi_i)$は容易に求めることができるため，
式(\ref{eq:xyz})と同様にして世界座標系における$星_i$の方向の単位ベクトル $(X'_i, Y'_i, Z'_i)^T$を算出することができる．

%\clearpage

世界座標系における星の方向ベクトルをリクティファイド座標系における方向ベクトルへ変換するために，\ref{ssec:position}条でGPSの位置情報から算出したカメラ間の方位角と仰角を使用する．
リクティファイド座標系における星の方向ベクトルの算出を図\ref{fig:ricthi_vector}に示す．図中のX軸，Y軸，Z軸はリクティファイド座標系の座標軸である．カメラAからカメラBへの方位角，仰角をそれぞれ$\alpha$，$\beta$とする．
ただし，$\alpha$はX'軸からY'軸へ向かう方向を正，$\beta$はX'Y'平面からZ'軸へ向かう方向を正とする．
このとき，反時計回りを正として座標系をY'軸周りに$\beta$，Z'軸周りに$\alpha$回転する回転行列$\mathbf{r_{\it \beta}}$，$\mathbf{r_{\alpha}}$は次の式(\ref{eq:rotation_matrix})で表される．

\begin{equation}
\mathbf{r_{\beta}}=
\begin{bmatrix}
\cos \beta &0 &\sin \beta\\
0 &1 &0\\
-\sin \beta &0 &\cos \beta
\end{bmatrix}
，\mathbf{r_{\alpha}}=
\begin{bmatrix}
\cos \alpha &\sin \alpha &0\\
-\sin \alpha &\cos \alpha &0\\
0 &0 &1
\end{bmatrix}
\label{eq:rotation_matrix}
\end{equation}

よって，リクティファイド座標系における$星_i$に向かう方向の単位ベクトル$\mathbf{m_{\it i}}$は次の式(\ref{eq:ricthi_vector})で求められる．

\begin{equation}
\mathbf{m_{\it i}}=
\begin{bmatrix}
X_i\\
Y_i\\
Z_i
\end{bmatrix}
=\mathbf{r_{\alpha}}\mathbf{r_{\beta}}
\begin{bmatrix}
X'_i\\
Y'_i\\
Z'_i
\end{bmatrix}
\label{eq:ricthi_vector}
\end{equation}


ここで，リクティファイド座標系からカメラ座標系への回転行列$\mathbf{R}$はN個の星全てにおいて式(\ref{eq:nRm})を満たす行列である．
よって，リクティファイド座標系における$星_i$の方向ベクトル$\mathbf{m_{\it i}}$と，カメラ座標系における$星_i$の方向ベクトル$\mathbf{n_{\it i}}$から，回転行列$\mathbf{R}$を用いたときの誤差$\mathbf{n}_i^\mathrm{T}\mathbf{R}\mathbf{m}_i$の総和が最小となるような回転行列$\mathbf{R}$を求めればよい．ゆえに，式(\ref{eq:hyoukaE})のような評価関数$E$を設定し，式(\ref{eq:saisyouR})のように$E$が最小となる回転行列$\mathbf{R}$をカメラA，カメラBの場合それぞれにおいて推定する．なお，推定の際には最急降下法を用いる．\\

\begin{equation}
 E=1-\frac{1}{N}\sum_{i=1}^{N}\left( \mathbf{n}_i^\mathrm{T}\mathbf{R}\mathbf{m}_i\right)
\label{eq:hyoukaE}
\end{equation}

\begin{equation}
 \mathbf{R}=\argmin_{R}E
\label{eq:saisyouR}
\end{equation}

\begin{figure}[hbp]
\begin{center}
\includegraphics[width=9cm]{./chap2/ricthi_vector3.eps}
\caption{世界座標系における星への方向ベクトルの算出}
\label{fig:world_vector}
\end{center}
\end{figure}

\begin{figure}[hbp]
\begin{center}
\includegraphics[width=11cm]{./chap2/ricthi_vector4.eps}
\caption{リクティファイド座標系における星への方向ベクトルの算出}
\label{fig:ricthi_vector}
\end{center}
\end{figure}



\clearpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{リクティファイド座標系画像への変換}
\label{sec:translation}
本節では，\ref{sec:calibration}節にて推定したパラメータを基に，画像を
\ref{sec:fish-eye_camera}節で定義したリクティファイド座標系に従う画像へと変換する手法について述べる．

画像の変換には，\ref{ssec:rotation}条にて推定した回転行列$\mathbf{R}$を用いる．
変換後の画像上の任意の点を$(U, V)$，それに対応する変換前の画像上の点を$(u, v)$とする．
\ref{sec:internal_parameter}項にて推定した画像中心$(C_u, C_v)$，歪みパラメータ$k$を使用し，
式(\ref{eq:ruv})--(\ref{eq:xyz})から，$(u, v)$に対応する3次元方向ベクトル$\mathbf{n}$が式(\ref{eq:n_vector})のように算出可能である．

\begin{equation}
\mathbf{n}=
\begin{bmatrix}
\frac{u - C_{u}}{k}\sqrt{1-\frac{r^2}{4k^2}}\\
\frac{v - C_{v}}{k}\sqrt{1-\frac{r^2}{4k^2}}\\
\frac{r^4}{2k^4}-\frac{2r^2}{k^2}+1
\end{bmatrix}
=
\begin{bmatrix}
x(u,v)\\
y(u,v)\\
z(u,v)
\end{bmatrix}
\label{eq:n_vector}
\end{equation}

ここで，回転行列$\mathbf{R}$はリクティファイド座標系からカメラ座標系へ変換する行列であるため，
式(\ref{eq:nRm})が成り立つ．
よって回転行列$\mathbf{R}$の逆行列$\mathbf{R}^{-1}$を式(\ref{eq:rotation_matrix_Inver})で表すと，
$(U, V)$に対応する3次元方向ベクトル$\mathbf{m}$は式(\ref{eq:m_vector})により得られ，
式(\ref{eq:m_vector})から極座標表示$(\theta，\phi)$は式(\ref{eq:theta_phi})により，$\mathbf{n}$の関数として表せる．

\begin{equation}
\mathbf{R}^{-1}=
\begin{bmatrix}
r_{11} &r_{12} &r_{13}\\
r_{21} &r_{22} &r_{23}\\
r_{31} &r_{32} &r_{33}
\end{bmatrix}
=
\begin{bmatrix}
\mathbf{r}_{1}\\
\mathbf{r}_{2}\\
\mathbf{r}_{3}
\end{bmatrix}
，\mathbf{r}_{k}=
\begin{bmatrix}
r_{k1} &r_{k2} &r_{k3}
\end{bmatrix}
（k=1,2,3）
\label{eq:rotation_matrix_Inver}
\end{equation}

\begin{equation}
\mathbf{m}=
\begin{bmatrix}
\sin\theta\cos\phi\\
\sin\theta\sin\phi\\
\cos\theta
\end{bmatrix}
=\mathbf{R}^{-1}\mathbf{n}=
\begin{bmatrix}
\mathbf{r}_{1}\mathbf{n}\\
\mathbf{r}_{2}\mathbf{n}\\
\mathbf{r}_{3}\mathbf{n}
\end{bmatrix}
\label{eq:m_vector}
\end{equation}

%\begin{equation}
%\theta= \arccos(\mathbf{r}_{3}\mathbf{n})= f(\mathbf{n}), \phi=\arctan(\frac{\mathbf{r}_{2}\mathbf{n}}{\mathbf{r}_{1}\mathbf{n}})=g(\mathbf{n})
%\label{eq:theta_phi}
%\end{equation}

\begin{equation}
\begin{bmatrix}
\theta\\
\phi
\end{bmatrix}
=
\begin{bmatrix}
\arccos(\mathbf{r}_{3}\mathbf{n})\\
\arctan(\frac{\mathbf{r}_{2}\mathbf{n}}{\mathbf{r}_{1}\mathbf{n}})
\end{bmatrix}
=
\begin{bmatrix}
f(\mathbf{n})\\
g(\mathbf{n})
\end{bmatrix}
\label{eq:theta_phi}
\end{equation}

また，式(\ref{eq:func_theta1})--(\ref{eq:func_phi1})から，$(U, V)$は式(\ref{eq:UV_uv})により$(\theta，\phi)$の関数で表せる．

\begin{equation}
\begin{bmatrix}
U\\
V
\end{bmatrix}
=
\begin{bmatrix}
C_u+2k\sin\frac{\theta}{2}\cos\phi\\
C_v+2k\sin\frac{\theta}{2}\sin\phi
\end{bmatrix}
=
\begin{bmatrix}
h(\theta,\phi)\\
i(\theta,\phi)
\end{bmatrix}
\label{eq:UV_uv}
\end{equation}

以上の式(\ref{eq:n_vector})--(\ref{eq:UV_uv})から，変換後の点$(U, V)$と，変換前の点$(u, v)$との対応が算出できるため，
リクティファイド座標系に従う画像を取得することが可能である．

リクティファイド座標系に従う画像へ変換前の画像の例を図\ref{fig:trans_in}，変換後の画像の例を図\ref{fig:trans_out}に示す．
カメラA，カメラBで撮影された画像中のオーロラ形状を目視でそれぞれ比較すると，図\ref{fig:trans_in}においては
カメラBで撮影されたものがカメラAで撮影されたものに対して時計回り方向に回転したようになっていることが確認できる．
一方で，変換後の図\ref{fig:trans_out}においては2枚の画像中のオーロラの向きが一致していることが分かる．


\begin{figure}[htb]
  \centering
  \subfigure[カメラA]{
    \includegraphics[width=5cm]{./chap2/PI1_before.eps}
  \label{fig:trans_in1}}
  \subfigure[カメラB]{
    \includegraphics[width=5cm]{./chap2/PI2_before.eps}
  \label{fig:trans_in2}}
  \caption{リクティファイド座標系への変換前画像}
  \label{fig:trans_in}
\end{figure}


\begin{figure}[htb]
  \centering
  \subfigure[カメラA]{
    \includegraphics[width=5cm]{./chap2/PI1_after.eps}
  \label{fig:trans_out1}}
  \subfigure[カメラB]{
    \includegraphics[width=5cm]{./chap2/PI2_after.eps}
  \label{fig:trans_out2}}
  \caption{リクティファイド座標系への変換後画像}
  \label{fig:trans_out}
\end{figure}

%（画像差し替え？）
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{魚眼画像から透視投影画像への変換}
\label{sec:undistortion}
魚眼カメラにより取得する画像は，魚眼レンズの性質により歪みを有する．本節では取得画像から魚眼レンズによる歪みを除去する手法について述べる．
この処理を補正面展開と呼ぶ．

本研究で使用する魚眼レンズの歪みは\ref{sec:fish-eye_camera}で述べた通り，式(\ref{eq:model})に従っている．
そこで式(\ref{eq:model})から屈折する前の画像を推定する．

補正面展開の様子を図\ref{fig:fisheye_ray}，図\ref{fig:hoseimen}に示す．図\ref{fig:fisheye_ray}は画像上の点からの入射光の展開の様子を上から見た模式図，
図\ref{fig:hoseimen}は図\ref{fig:fisheye_ray}を下方から上方へ向けて模式的に表した図を示している．
補正面展開前の任意の点$(x_p, y_p)$が補正面展開後の画像上で$(X_p, Y_p)$となるとし，任意の画角$\omega$ の範囲にて補正面展開を行う．
また，補正面展開後の画像の高さ，幅をそれぞれH，Wとし，図\ref{fig:fisheye_ray}のように距離$Z_v$を設定する．

魚眼レンズによる歪みは画像中心から放射方向のみであるから，補正面展開前の画像中心から任意の点$(x_p, y_p)$までの距離を$r$，補正面展開後の画像中心から対応する点$(X_p, Y_p)$までの距離を$R$とすると，
図\ref{fig:fisheye_ray}，図\ref{fig:hoseimen}より，$(x_p, y_p)$，$(X_p, Y_p)$は次のような関係を持つ．

\begin{eqnarray}
\left[\begin{array}{cc}x_p\\y_p \end{array}\right] = \frac{r}{R} \left[\begin{array}{cc}X_p \\ Y_p \end{array}\right]
\label{eq:XY}
\end{eqnarray}

よって，補正面展開後の画像上の点$(X_p, Y_p)$に対応する補正面展開前の画像上の点$(x_p, y_p)$を求めるためには$r$，$R$の値が求まれば良い．
ここで，$R$は図\ref{fig:fisheye_ray}より，次式(\ref{eq:R})により求まる．

\begin{eqnarray}
R = \sqrt{ X_p^2 + Y_p^2}
\label{eq:R}
\end{eqnarray}

また，$r$は式(\ref{eq:model})より，$\theta$の値が定まれば算出できる．$\theta$の値は次式(\ref{eq:theta})，(\ref{eq:Zv})により算出される．
したがって$r$は式(\ref{eq:r_p})により，$X_p$，$Y_p$，$Z_p$の関数で表される．

\begin{eqnarray}
\theta = \cos^{-1} \frac{Zv}{\sqrt{ X_p^2 + Y_p^2 + Z_v^2} }
\label{eq:theta}
\end{eqnarray}

\begin{eqnarray}
Z_v = \frac{W}{ 2\tan{\frac{\omega}{2}} }
\label{eq:Zv}
\end{eqnarray}

\begin{eqnarray}
r = f(X_p,Y_p,Z_p)
\label{eq:r_p}
\end{eqnarray}

以上の関係式に基づき，補正面展開を行う．

\begin{figure}[htb]
\begin{center}
\includegraphics[width=7cm]{./chap2/fisheye_ray.eps}
\vspace{-0.5cm}
\caption{魚眼レンズへの入射光の展開の様子}
\label{fig:fisheye_ray}
\end{center}
\end{figure}

\begin{figure}[htb]
\begin{center}
\includegraphics[width=7cm]{./chap2/hoseimen.eps}
\caption{補正面展開による点の展開の様子}
\label{fig:hoseimen}
\end{center}
\end{figure}

\clearpage

補正面展開を行う前の画像の例を図\ref{fig:before_expansion_120}，その画像に対して補正面展開を行った後の画像を図\ref{fig:after_expansion_120}に示す．
図\ref{fig:before_expansion_120}中において魚眼レンズにより歪んでいた線が，図\ref{fig:after_expansion_120}の補正面展開後の画像中では直線になっていることが確認できる．


\begin{figure}[htb]
\begin{center}
\includegraphics[width=7cm]{./chap2/before_expansion.eps}
\caption{補正面展開前の画像の例（魚眼カメラでの取得画像）}
\label{fig:before_expansion_120}
\end{center}
\end{figure}

\vspace{-0.5cm}

\begin{figure}[htb]
\begin{center}
\includegraphics[width=7cm]{./chap2/after_expansion.eps}
\caption{補正面展開後の画像の例}
\label{fig:after_expansion_120}
\end{center}
\end{figure}

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{おわりに}


\clearpage



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Local Variables:
%%% mode: katex
%%% TeX-master: "../thesis"
%%% End:
